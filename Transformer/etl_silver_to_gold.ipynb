{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-silver-gold",
   "metadata": {},
   "source": [
    "# ETL SILVER -> GOLD (PostgreSQL)\n",
    "**Origem:** Tabela `silver.USER` (PostgreSQL)  \n",
    "**Destino:** Schema `dw` (Star Schema)  \n",
    "**Objetivo:** Modelagem dimensional com Surrogate Keys (SK/SRK) em **todas** as tabelas (Dimensões e Fato)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-env",
   "metadata": {},
   "source": [
    "## 1. Configuração e Conexão\n",
    "Definição das credenciais e conexão com o banco para leitura da Silver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "import-libs",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_batch\n",
    "\n",
    "# Configurações do Banco\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'port': 5432,\n",
    "    'database': 'instagram_usage',\n",
    "    'user': 'sbd2',\n",
    "    'password': 'sbd2123'\n",
    "}\n",
    "\n",
    "# Schemas\n",
    "SOURCE_SCHEMA = 'silver'\n",
    "SOURCE_TABLE = 'USER'\n",
    "TARGET_SCHEMA = 'dw'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extract-silver",
   "metadata": {},
   "source": [
    "## 2. Extract: Ler dados da Silver\n",
    "Leitura direta do PostgreSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load-df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_silver_data():\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    query = f\"SELECT * FROM {SOURCE_SCHEMA}.\\\"{SOURCE_TABLE}\\\"\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "df_silver = get_silver_data()\n",
    "\n",
    "# Garantir datetime\n",
    "df_silver['last_login_date'] = pd.to_datetime(df_silver['last_login_date'])\n",
    "print(f\"Registros carregados da Silver: {len(df_silver)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transform-dims",
   "metadata": {},
   "source": [
    "## 3. Transform: Criação das Dimensões com Surrogate Keys (SK)\n",
    "Geração de chaves sequenciais artificiais para cada dimensão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-dims",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Dimensão Date ---\n",
    "dates = df_silver['last_login_date'].unique()\n",
    "dim_date = pd.DataFrame({'date_iso': dates})\n",
    "dim_date = dim_date.sort_values('date_iso').reset_index(drop=True)\n",
    "\n",
    "# Criar SK_Date (SRK)\n",
    "dim_date['srk_date'] = dim_date.index + 1\n",
    "\n",
    "dim_date['day'] = dim_date['date_iso'].dt.day\n",
    "dim_date['month'] = dim_date['date_iso'].dt.month\n",
    "dim_date['year'] = dim_date['date_iso'].dt.year\n",
    "dim_date['quarter'] = dim_date['date_iso'].dt.quarter\n",
    "dim_date['day_of_week'] = dim_date['date_iso'].dt.day_name()\n",
    "\n",
    "# --- 2. Dimensão Demographics ---\n",
    "dim_demographics = df_silver[[\n",
    "    'user_id', 'age', 'gender', 'country', 'urban_rural', 'income_level', \n",
    "    'employment_status', 'education_level', 'relationship_status', 'has_children'\n",
    "]].copy()\n",
    "\n",
    "dim_demographics['srk_demographics'] = range(1, len(dim_demographics) + 1)\n",
    "dim_demographics.rename(columns={'user_id': 'srk_user_id'}, inplace=True)\n",
    "\n",
    "# --- 3. Dimensão Lifestyle ---\n",
    "dim_lifestyle = df_silver[[\n",
    "    'user_id', 'exercise_hours_per_week', 'sleep_hours_per_night', 'diet_quality', \n",
    "    'smoking', 'alcohol_frequency', 'body_mass_index', \n",
    "    'blood_pressure_systolic', 'blood_pressure_diastolic', \n",
    "    'hobbies_count', 'social_events_per_month', 'books_read_per_year', \n",
    "    'volunteer_hours_per_month', 'travel_frequency_per_year'\n",
    "]].copy()\n",
    "\n",
    "dim_lifestyle['srk_lifestyle'] = range(1, len(dim_lifestyle) + 1)\n",
    "dim_lifestyle.rename(columns={'user_id': 'srk_user_id'}, inplace=True)\n",
    "\n",
    "# --- 4. Dimensão Security & Privacy ---\n",
    "dim_security = df_silver[[\n",
    "    'user_id', 'privacy_setting_level', 'two_factor_auth_enabled', \n",
    "    'biometric_login_used', 'linked_accounts_count'\n",
    "]].copy()\n",
    "\n",
    "dim_security['srk_security'] = range(1, len(dim_security) + 1)\n",
    "dim_security.rename(columns={'user_id': 'srk_user_id'}, inplace=True)\n",
    "# --- 5. Dimensão App Preferences ---\n",
    "dim_app = df_silver[[\n",
    "    'user_id', 'app_name', 'account_creation_year', 'uses_premium_features', \n",
    "    'subscription_status', 'content_type_preference', 'preferred_content_theme'\n",
    "]].copy()\n",
    "\n",
    "dim_app['srk_app_profile'] = range(1, len(dim_app) + 1)\n",
    "dim_app.rename(columns={'user_id': 'srk_user_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transform-fact",
   "metadata": {},
   "source": [
    "## 4. Transform: Montagem da Fato com SRK Própria\n",
    "Agora a tabela fato também ganha sua própria Surrogate Key (`sk_fact_ads_performance`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-fact",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleciona métricas da Silver\n",
    "fact_table = df_silver[[\n",
    "    'user_id', 'last_login_date', \n",
    "    'ads_clicked_per_day', 'ads_viewed_per_day', \n",
    "    'daily_active_minutes_instagram', 'sessions_per_day', 'posts_created_per_week', \n",
    "    'reels_watched_per_day', 'stories_viewed_per_day', 'likes_given_per_day', \n",
    "    'comments_written_per_day', 'dms_sent_per_week', 'dms_received_per_week', \n",
    "    'time_on_feed_per_day', 'time_on_explore_per_day', 'time_on_messages_per_day', \n",
    "    'time_on_reels_per_day', 'average_session_length_minutes', \n",
    "    'notification_response_rate', 'user_engagement_score',\n",
    "    'perceived_stress_score', 'self_reported_happiness', 'daily_steps_count',\n",
    "    'weekly_work_hours', 'followers_count', 'following_count'\n",
    "]].copy()\n",
    "\n",
    "# JOIN para pegar SK_DATE\n",
    "fact_table = fact_table.merge(dim_date[['date_iso', 'sk_date']], left_on='last_login_date', right_on='date_iso', how='left')\n",
    "\n",
    "# JOIN para pegar SKs das outras dimensões\n",
    "fact_table = fact_table.merge(dim_demographics[['nk_user_id', 'sk_demographics']], left_on='user_id', right_on='nk_user_id', how='left')\n",
    "fact_table = fact_table.merge(dim_lifestyle[['nk_user_id', 'sk_lifestyle']], left_on='user_id', right_on='nk_user_id', how='left')\n",
    "fact_table = fact_table.merge(dim_security[['nk_user_id', 'sk_security']], left_on='user_id', right_on='nk_user_id', how='left')\n",
    "fact_table = fact_table.merge(dim_app[['nk_user_id', 'sk_app_profile']], left_on='user_id', right_on='nk_user_id', how='left')\n",
    "\n",
    "# Calcular CTR\n",
    "fact_table['click_through_rate'] = fact_table.apply(\n",
    "    lambda x: x['ads_clicked_per_day'] / x['ads_viewed_per_day'] if x['ads_viewed_per_day'] > 0 else 0, axis=1\n",
    ")\n",
    "\n",
    "# --- ATUALIZAÇÃO: CRIAR SRK PARA A FATO ---\n",
    "# Cria uma chave única sequencial para cada registro da fato\n",
    "fact_table['srk_fact_ads_performance'] = range(1, len(fact_table) + 1)\n",
    "\n",
    "# Limpeza final (Remover colunas temporárias)\n",
    "cols_to_drop = ['user_id', 'last_login_date', 'date_iso', 'nk_user_id_x', 'nk_user_id_y']\n",
    "fact_table.drop(columns=[c for c in cols_to_drop if c in fact_table.columns], inplace=True)\n",
    "\n",
    "# Reordenar colunas: SK da Fato -> SKs Dimensões -> Métricas\n",
    "sk_cols = ['srk_fact_ads_performance', 'sk_date', 'sk_demographics', 'sk_lifestyle', 'sk_security', 'sk_app_profile']\n",
    "metric_cols = [c for c in fact_table.columns if c not in sk_cols]\n",
    "fact_table = fact_table[sk_cols + metric_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-gold",
   "metadata": {},
   "source": [
    "## 5. Load: Carga no Schema DW\n",
    "Criação das tabelas e inserção dos dados com PKs definidas para todos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_dw(df, table_name, pk_col):\n",
    "    try:\n",
    "        with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(f\"CREATE SCHEMA IF NOT EXISTS {TARGET_SCHEMA};\")\n",
    "                cur.execute(f\"DROP TABLE IF EXISTS {TARGET_SCHEMA}.{table_name} CASCADE;\")\n",
    "                \n",
    "                # DDL Dinâmico\n",
    "                create_query = f\"CREATE TABLE {TARGET_SCHEMA}.{table_name} (\"\n",
    "                for col in df.columns:\n",
    "                    dtype = 'TEXT'\n",
    "                    # Se for a coluna definida como PK, recebe INTEGER PRIMARY KEY\n",
    "                    if col == pk_col:\n",
    "                        dtype = 'INTEGER PRIMARY KEY'\n",
    "                    # Se for outra coluna SK (FK), recebe INTEGER\n",
    "                    elif col.startswith('sk_'):\n",
    "                        dtype = 'INTEGER'\n",
    "                    elif df[col].dtype == 'float64':\n",
    "                        dtype = 'FLOAT'\n",
    "                    elif df[col].dtype == 'int64':\n",
    "                        dtype = 'INTEGER'\n",
    "                    elif df[col].dtype == 'bool':\n",
    "                        dtype = 'BOOLEAN'\n",
    "                    elif 'date' in str(df[col].dtype):\n",
    "                         dtype = 'TIMESTAMP'\n",
    "                    \n",
    "                    create_query += f\"{col} {dtype}, \"\n",
    "                \n",
    "                create_query = create_query.rstrip(', ') + \");\"\n",
    "                cur.execute(create_query)\n",
    "                \n",
    "                # Insert\n",
    "                cols_list = df.columns.tolist()\n",
    "                placeholders = \", \".join([\"%s\"] * len(cols_list))\n",
    "                colnames = \", \".join(cols_list)\n",
    "                insert_sql = f\"INSERT INTO {TARGET_SCHEMA}.{table_name} ({colnames}) VALUES ({placeholders});\"\n",
    "                \n",
    "                data_to_insert = [tuple(x) for x in df.to_numpy()]\n",
    "                execute_batch(cur, insert_sql, data_to_insert, page_size=5000)\n",
    "                print(f\"Tabela {table_name} carregada com {len(data_to_insert)} linhas.\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar {table_name}: {e}\")\n",
    "\n",
    "# Executar Cargas (Agora passando a PK da fato também)\n",
    "print(\"--- Iniciando Carga no DW ---\")\n",
    "load_to_dw(dim_date, 'dim_date', 'sk_date')\n",
    "load_to_dw(dim_demographics, 'dim_demographics', 'sk_demographics')\n",
    "load_to_dw(dim_lifestyle, 'dim_lifestyle', 'sk_lifestyle')\n",
    "load_to_dw(dim_security, 'dim_security', 'sk_security')\n",
    "load_to_dw(dim_app, 'dim_app_preferences', 'sk_app_profile')\n",
    "\n",
    "# Tabela Fato agora tem PK definida: 'sk_fact_ads_performance'\n",
    "load_to_dw(fact_table, 'fact_ads_performance', 'sk_fact_ads_performance') \n",
    "print(\"--- Carga Finalizada ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
