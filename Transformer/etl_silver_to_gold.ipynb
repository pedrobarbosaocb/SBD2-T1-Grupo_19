{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff963708",
   "metadata": {},
   "source": [
    "# ETL: Camada Silver $\\rightarrow$ Camada Gold (Data Warehouse)\n",
    "\n",
    "**Projeto:** Social Media User Analysis  \n",
    "**Origem:** Schema `silver` (PostgreSQL - Tabela tratada)  \n",
    "**Destino:** Schema `dw` (PostgreSQL - Modelagem Dimensional Star Schema)\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivo\n",
    "Transformar os dados limpos da camada Silver em um modelo dimensional otimizado para consultas anal√≠ticas (OLAP). O modelo escolhido √© o Star Schema, composto por 2 Tabelas Fato e 4 Tabelas Dimens√£o.\n",
    "\n",
    "## Arquitetura do Data Warehouse\n",
    "\n",
    "### 1. Tabelas Fato (M√©tricas)\n",
    "* **`FT_ADS_PRF` (Ads Performance):** Foca na efici√™ncia da publicidade (Views, Cliques, CTR).\n",
    "* **`FT_ENG_APP` (Engajamento App):** Foca no comportamento do usu√°rio (Likes, Coment√°rios, Tempo de Tela).\n",
    "\n",
    "### 2. Tabelas Dimens√£o (Contexto)\n",
    "* **`DIM_USR` (Usu√°rio):** Dados demogr√°ficos (Idade, G√™nero, Pa√≠s).\n",
    "* **`DIM_ETL_VDA` (Estilo de Vida):** Sa√∫de e h√°bitos (Sono, Exerc√≠cio, Felicidade).\n",
    "* **`DIM_CNT` (Conta):** Configura√ß√µes do app (Premium, Privacidade, Data de Cria√ß√£o).\n",
    "* **`DIM_ITR` (Interesse):** Prefer√™ncias de conte√∫do (Tech, Fashion, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d74c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_batch\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message='.*SQLAlchemy.*')\n",
    "     \n",
    "# --- CONFIGURA√á√ïES DE CONEX√ÉO ---\n",
    "DB_HOST = \"localhost\"\n",
    "DB_NAME = \"instagram_usage\"\n",
    "DB_USER = \"sbd2\"\n",
    "DB_PASS = \"sbd2123\"  \n",
    "\n",
    "# Schemas\n",
    "SILVER_SCHEMA = \"silver\"\n",
    "SILVER_TABLE = \"user\"\n",
    "GOLD_SCHEMA = \"dw\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33101bca",
   "metadata": {},
   "source": [
    "## Etapa 1: Extra√ß√£o\n",
    "Nesta etapa, conectamos ao banco de dados PostgreSQL e lemos todos os dados da tabela `silver.social_media_silver`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d2cddae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados carregados da camada Silver com sucesso!\n",
      " Registros: 1506286 | Colunas: 58\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn = psycopg2.connect(host=DB_HOST, database=DB_NAME, user=DB_USER, password=DB_PASS)\n",
    "    query = f\"SELECT * FROM {SILVER_SCHEMA}.{SILVER_TABLE}\"\n",
    "    \n",
    "    # Leitura para DataFrame\n",
    "    df_silver = pd.read_sql(query, conn)\n",
    "    print(f\"Dados carregados da camada Silver com sucesso!\")\n",
    "    print(f\" Registros: {df_silver.shape[0]} | Colunas: {df_silver.shape[1]}\")\n",
    "    \n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"Erro na extra√ß√£o: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25d0808",
   "metadata": {},
   "source": [
    "##  Etapa 2: Transforma√ß√£o\n",
    "\n",
    "Aqui ocorre a modelagem dimensional. O processo √© dividido em sub-etapas:\n",
    "\n",
    "1.  **Mapeamento de Colunas:** Defini√ß√£o dos dicion√°rios `De -> Para` para aplicar os nomes mnem√¥nicos (ex: `age` vira `AGE_USR`).\n",
    "2.  **Cria√ß√£o das Dimens√µes:**\n",
    "    * Selecionamos as colunas de atributos √∫nicos.\n",
    "    * Aplicamos `drop_duplicates()` para garantir que cada perfil exista apenas uma vez.\n",
    "    * Geramos as **Surrogate Keys (SRK)** sequenciais (1, 2, 3...) para identificar cada linha.\n",
    "3.  **Cria√ß√£o das Fatos:**\n",
    "    * Fazemos o `merge` (Join) da tabela base com as Dimens√µes criadas para recuperar os IDs (`SRK`) corretos.\n",
    "    * Separamos as m√©tricas de Ads e Engajamento em dois DataFrames distintos.\n",
    "    * Geramos uma `SRK` pr√≥pria para cada tabela fato (`SRK_ADS` e `SRK_ENG`), conforme requisito do projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b17a160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.1 Dicion√°rios de Mapeamento  ---\n",
    "\n",
    "# Mapeamento: Usu√°rio\n",
    "map_usuario = {\n",
    "    'sk_usuario': 'SRK_USR', 'user_id': 'SRK_USR', \n",
    "    'age': 'AGE_USR', 'gender': 'GEN_USR', 'country': 'CTR_USR',\n",
    "    'urban_rural': 'URB_RRL', 'education_level': 'EDU_LVL',\n",
    "    'employment_status': 'EMP_STS', 'income_level': 'INC_LVL',\n",
    "    'relationship_status': 'REL_STS', 'has_children': 'HAS_CHD'\n",
    "}\n",
    "\n",
    "# Mapeamento: Estilo de Vida\n",
    "map_estilovida = {\n",
    "    'sk_estilovida': 'SRK_ETL_VDA',\n",
    "    'exercise_hours_per_week': 'EXE_HRS_WEK', 'sleep_hours_per_night': 'SLP_HRS_NGT',\n",
    "    'diet_quality': 'DIT_QLT', 'body_mass_index': 'BDY_MAS_IDX',\n",
    "    'blood_pressure_systolic': 'BLD_PRS_SYS', 'blood_pressure_diastolic': 'BLD_PRS_DIA',\n",
    "    'daily_steps_count': 'DLY_STP_CNT', 'perceived_stress_score': 'STR_SCR',\n",
    "    'self_reported_happiness': 'HPN_SCR', 'smoking': 'SMK_FLG',\n",
    "    'alcohol_frequency': 'ALC_FRQ', 'weekly_work_hours': 'WRK_HRS_WEK',\n",
    "    'hobbies_count': 'HOB_CNT', 'social_events_per_month': 'SOC_EVT_MTH',\n",
    "    'books_read_per_year': 'BKS_RED_YAR', 'volunteer_hours_per_month': 'VOL_HRS_MTH',\n",
    "    'travel_frequency_per_year': 'TRV_FRQ_YAR'\n",
    "}\n",
    "\n",
    "# Mapeamento: Conta\n",
    "map_conta = {\n",
    "    'sk_conta': 'SRK_CNT',\n",
    "    'app_name': 'APP_NME', 'account_creation_year': 'ACC_CRT_YAR',\n",
    "    'last_login_date': 'LST_LOG_DTE', 'subscription_status': 'SUB_STS',\n",
    "    'uses_premium_features': 'USE_PRM_FTR', 'privacy_setting_level': 'PRV_LVL',\n",
    "    'two_factor_auth_enabled': 'TWO_FAC_AUT', 'biometric_login_used': 'BIO_LOG_USE'\n",
    "}\n",
    "\n",
    "# Mapeamento: Interesse\n",
    "map_interesse = {\n",
    "    'sk_interesse': 'SRK_ITR',\n",
    "    'content_type_preference': 'CNT_TYP_PRF',\n",
    "    'preferred_content_theme': 'CNT_TME_PRF'\n",
    "}\n",
    "\n",
    "# Mapeamento: Chaves Estrangeiras nas Fatos\n",
    "map_fatos_fk = {\n",
    "    'sk_usuario': 'SRK_USR', 'sk_estilovida': 'SRK_ETL_VDA',\n",
    "    'sk_conta': 'SRK_CNT', 'sk_interesse': 'SRK_ITR'\n",
    "}\n",
    "\n",
    "# M√©tricas das Fatos\n",
    "map_ads = {'ads_viewed_per_day': 'ADS_VIW_DIA', 'ads_clicked_per_day': 'ADS_CLK_DIA'}\n",
    "\n",
    "map_eng = {\n",
    "    'daily_active_minutes_instagram': 'DLY_ACT_MIN', 'sessions_per_day': 'SES_DIA',\n",
    "    'average_session_length_minutes': 'AVG_SES_MIN', 'user_engagement_score': 'ENG_SCR',\n",
    "    'likes_given_per_day': 'LIK_GVN_DIA', 'comments_written_per_day': 'COM_WRT_DIA',\n",
    "    'posts_created_per_week': 'PST_CRT_WEK', 'dms_sent_per_week': 'DMS_SNT_WEK',\n",
    "    'dms_received_per_week': 'DMS_RCV_WEK', 'reels_watched_per_day': 'RLS_WCH_DIA',\n",
    "    'stories_viewed_per_day': 'STR_VIW_DIA', 'time_on_feed_per_day': 'TIM_FED_DIA',\n",
    "    'time_on_explore_per_day': 'TIM_EXP_DIA', 'time_on_reels_per_day': 'TIM_RLS_DIA',\n",
    "    'time_on_messages_per_day': 'TIM_MSG_DIA', 'followers_count': 'FOL_CNT',\n",
    "    'following_count': 'FLW_CNT', 'linked_accounts_count': 'LNK_ACC_CNT',\n",
    "    'notification_response_rate': 'NTF_RSP_RAT'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d79af53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimens√µes geradas com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# --- 2.2 Gera√ß√£o das Tabelas Dimens√£o ---\n",
    "\n",
    "# 1. DIM_USR (Dimens√£o Usu√°rio)\n",
    "cols_attrs_usuario = ['age', 'gender', 'country', 'urban_rural', 'income_level', \n",
    "                      'employment_status', 'education_level', 'relationship_status', 'has_children']\n",
    "\n",
    "dim_usuario = df_silver[['user_id'] + cols_attrs_usuario].drop_duplicates().reset_index(drop=True)\n",
    "dim_usuario['sk_usuario'] = dim_usuario['user_id']\n",
    "dim_usuario = dim_usuario[['sk_usuario'] + cols_attrs_usuario]\n",
    "dim_usuario.rename(columns=map_usuario, inplace=True)\n",
    "\n",
    "# 2. DIM_ETL_VDA (Dimens√£o Estilo de Vida)\n",
    "# Estrat√©gia: Criar ID sequencial novo\n",
    "cols_estilovida = list(map_estilovida.keys())\n",
    "cols_estilovida.remove('sk_estilovida')\n",
    "dim_estilovida = df_silver[cols_estilovida].drop_duplicates().reset_index(drop=True)\n",
    "dim_estilovida['sk_estilovida'] = dim_estilovida.index + 1\n",
    "dim_estilovida = dim_estilovida[['sk_estilovida'] + cols_estilovida]\n",
    "dim_estilovida.rename(columns=map_estilovida, inplace=True)\n",
    "\n",
    "# 3. DIM_CNT (Dimens√£o Conta)\n",
    "cols_conta = list(map_conta.keys())\n",
    "cols_conta.remove('sk_conta')\n",
    "dim_conta = df_silver[cols_conta].drop_duplicates().reset_index(drop=True)\n",
    "dim_conta['sk_conta'] = dim_conta.index + 1\n",
    "dim_conta = dim_conta[['sk_conta'] + cols_conta]\n",
    "dim_conta.rename(columns=map_conta, inplace=True)\n",
    "\n",
    "# 4. DIM_ITR (Dimens√£o Interesse)\n",
    "cols_interesse = list(map_interesse.keys())\n",
    "cols_interesse.remove('sk_interesse')\n",
    "dim_interesse = df_silver[cols_interesse].drop_duplicates().reset_index(drop=True)\n",
    "dim_interesse['sk_interesse'] = dim_interesse.index + 1\n",
    "dim_interesse = dim_interesse[['sk_interesse'] + cols_interesse]\n",
    "dim_interesse.rename(columns=map_interesse, inplace=True)\n",
    "\n",
    "print(\"Dimens√µes geradas com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3a6370b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fatos geradas com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# --- 2.3 Gera√ß√£o das Tabelas Fato ---\n",
    "\n",
    "# Prepara√ß√£o: Unir a base original com as Dimens√µes criadas para pegar os IDs (FKs)\n",
    "fato_base = df_silver.copy()\n",
    "fato_base['sk_usuario'] = fato_base['user_id'] # SRK_USR √© igual ao ID\n",
    "\n",
    "# Merge (Left Join) para buscar as chaves SRK_ETL_VDA, SRK_CNT, SRK_ITR\n",
    "# Utilizamos as colunas de atributos como chave de busca\n",
    "fato_base = fato_base.merge(dim_estilovida.rename(columns={v:k for k,v in map_estilovida.items()}), \n",
    "                            on=list(map_estilovida.keys())[1:], how='left')\n",
    "fato_base = fato_base.merge(dim_conta.rename(columns={v:k for k,v in map_conta.items()}), \n",
    "                            on=list(map_conta.keys())[1:], how='left')\n",
    "fato_base = fato_base.merge(dim_interesse.rename(columns={v:k for k,v in map_interesse.items()}), \n",
    "                            on=list(map_interesse.keys())[1:], how='left')\n",
    "\n",
    "cols_fk = ['sk_usuario', 'sk_estilovida', 'sk_conta', 'sk_interesse']\n",
    "\n",
    "# --- FATO 1: FT_ADS_PRF (Performance de Ads) ---\n",
    "cols_ads = list(map_ads.keys())\n",
    "fato_ads = fato_base[cols_fk + cols_ads].copy()\n",
    "fato_ads.rename(columns={**map_fatos_fk, **map_ads}, inplace=True)\n",
    "\n",
    "# Gerando chave prim√°ria pr√≥pria (SRK_ADS)\n",
    "fato_ads.reset_index(drop=True, inplace=True)\n",
    "fato_ads['SRK_ADS'] = fato_ads.index + 1\n",
    "cols_order_ads = ['SRK_ADS'] + [c for c in fato_ads.columns if c != 'SRK_ADS']\n",
    "fato_ads = fato_ads[cols_order_ads]\n",
    "\n",
    "# --- FATO 2: FT_ENG_APP (Engajamento do App) ---\n",
    "cols_eng = list(map_eng.keys())\n",
    "fato_eng = fato_base[cols_fk + cols_eng].copy()\n",
    "fato_eng.rename(columns={**map_fatos_fk, **map_eng}, inplace=True)\n",
    "\n",
    "# Gerando chave prim√°ria pr√≥pria (SRK_ENG)\n",
    "fato_eng.reset_index(drop=True, inplace=True)\n",
    "fato_eng['SRK_ENG'] = fato_eng.index + 1\n",
    "cols_order_eng = ['SRK_ENG'] + [c for c in fato_eng.columns if c != 'SRK_ENG']\n",
    "fato_eng = fato_eng[cols_order_eng]\n",
    "\n",
    "print(f\"Fatos gerados com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc621ac9",
   "metadata": {},
   "source": [
    "##  Etapa 3: Carga\n",
    "\n",
    "A etapa final persiste os DataFrames transformados no banco de dados.\n",
    "\n",
    "**Estrat√©gia de Carga:** `Full Refresh` (Truncate & Insert)\n",
    "1.  Limpamos as tabelas existentes (TRUNCATE CASCADE) para evitar duplica√ß√£o.\n",
    "2.  Inserimos os dados em lote (Batch Insert) para alta performance.\n",
    "\n",
    "**Ordem de Inser√ß√£o (Cr√≠tica para Integridade Referencial):**\n",
    "1.  **Dimens√µes** (Pois as fatos dependem delas).\n",
    "2.  **Fatos** (Que referenciam as dimens√µes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5729bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Iniciando Carga no Data Warehouse...\n",
      "   ‚úÖ Tabelas antigas limpas.\n",
      "   -> Inseridos 1506286 registros em DIM_USR\n",
      "   -> Inseridos 1506286 registros em DIM_ETL_VDA\n",
      "   -> Inseridos 315973 registros em DIM_CNT\n",
      "   -> Inseridos 48 registros em DIM_ITR\n",
      "   -> Inseridos 1506286 registros em FT_ADS_PRF\n",
      "   -> Inseridos 1506286 registros em FT_ENG_APP\n",
      "\n",
      "SUCESSO! Carga ETL conclu√≠da. O Data Warehouse est√° atualizado.\n"
     ]
    }
   ],
   "source": [
    "def insert_data(cur, df, table_name):\n",
    "    \"\"\"\n",
    "    Fun√ß√£o auxiliar para inserir dados em lote no PostgreSQL.\n",
    "    \"\"\"\n",
    "    if df.empty: \n",
    "        return\n",
    "    \n",
    "    # Prepara a query SQL din√¢mica\n",
    "    cols = df.columns.tolist()\n",
    "    cols_str = \", \".join(cols)\n",
    "    placeholders = \", \".join([\"%s\"] * len(cols))\n",
    "    sql = f\"INSERT INTO {GOLD_SCHEMA}.{table_name} ({cols_str}) VALUES ({placeholders})\"\n",
    "    \n",
    "    # Convers√£o de dados (DataFrame -> Lista de Tuplas)\n",
    "    # .replace({np.nan: None}) garante que NaNs virem NULL no SQL\n",
    "    data = [tuple(x) for x in df.replace({np.nan: None}).to_numpy().tolist()]\n",
    "    \n",
    "    try:\n",
    "        execute_batch(cur, sql, data)\n",
    "        print(f\"   -> Inseridos {len(data)} registros em {table_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   -> Erro ao inserir em {table_name}: {e}\")\n",
    "        raise e\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(host=DB_HOST, database=DB_NAME, user=DB_USER, password=DB_PASS)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    print(\"Iniciando Carga no Data Warehouse...\")\n",
    "    \n",
    "    # 1. Limpeza (Ordem: Fatos primeiro, depois Dimens√µes devido a FKs)\n",
    "    tables_to_clear = ['FT_ADS_PRF', 'FT_ENG_APP', 'DIM_USR', 'DIM_ETL_VDA', 'DIM_CNT', 'DIM_ITR']\n",
    "    for t in tables_to_clear:\n",
    "        cur.execute(f\"TRUNCATE TABLE {GOLD_SCHEMA}.{t} CASCADE;\")\n",
    "    print(\" Tabelas antigas limpas.\")\n",
    "    \n",
    "    # 2. Inser√ß√£o das Dimens√µes\n",
    "    insert_data(cur, dim_usuario, 'DIM_USR')\n",
    "    insert_data(cur, dim_estilovida, 'DIM_ETL_VDA')\n",
    "    insert_data(cur, dim_conta, 'DIM_CNT')\n",
    "    insert_data(cur, dim_interesse, 'DIM_ITR')\n",
    "    \n",
    "    # 3. Inser√ß√£o das Fatos\n",
    "    insert_data(cur, fato_ads, 'FT_ADS_PRF')\n",
    "    insert_data(cur, fato_eng, 'FT_ENG_APP')\n",
    "    \n",
    "    conn.commit()\n",
    "    print(\"\\nSUCESSO! Carga ETL conclu√≠da. O Data Warehouse est√° atualizado.\")\n",
    "\n",
    "except Exception as e:\n",
    "    conn.rollback()\n",
    "    print(f\"\\nFALHA CR√çTICA na carga: {e}\")\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5d905f-1eb3-4fd6-b115-4780cd5d6c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
